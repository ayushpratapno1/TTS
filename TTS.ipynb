{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMM1b4sa2KkW9dMvZMbs2JL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushpratapno1/TTS/blob/main/TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Implementation Code***"
      ],
      "metadata": {
        "id": "tlCJsf1TZn8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Environment Setup and GPU Check"
      ],
      "metadata": {
        "id": "ZACbTDMXZ-N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"No GPU available - will use CPU\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "moew57dccygn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Mount Google Drive (Optional for saving models)"
      ],
      "metadata": {
        "id": "_y4pvrNMaPAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directory for saving models\n",
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/TTS_Models', exist_ok=True)\n",
        "print(\"Google Drive mounted successfully!\")"
      ],
      "metadata": {
        "id": "y3XhKl0maRqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Install Dependencies"
      ],
      "metadata": {
        "id": "spJl1GoUaVqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages with proper versions for Colab\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q transformers==4.35.0\n",
        "!pip install -q datasets==2.14.0\n",
        "!pip install -q soundfile==0.12.1\n",
        "!pip install -q librosa==0.10.1\n",
        "!pip install -q gradio==4.0.0\n",
        "!pip install -q evaluate==0.4.0\n",
        "!pip install -q accelerate==0.24.0\n",
        "!pip install -q peft==0.6.0\n",
        "\n",
        "print(\"All packages installed successfully!\")"
      ],
      "metadata": {
        "id": "0cKE5ziPaYso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Import Libraries"
      ],
      "metadata": {
        "id": "IwmDAOp5acxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "from transformers import (\n",
        "    SpeechT5ForTextToSpeech,\n",
        "    SpeechT5HifiGan,\n",
        "    SpeechT5Processor,\n",
        "    SpeechT5Tokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    set_seed\n",
        ")\n",
        "\n",
        "from datasets import load_dataset, Dataset, Audio, concatenate_datasets\n",
        "import gradio as gr\n",
        "from evaluate import load\n",
        "from IPython.display import Audio as IPAudio, display\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed(42)\n",
        "print(\"Libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "L2C6OAS3agkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Model Class Definition"
      ],
      "metadata": {
        "id": "jmFbCh1CayWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IndicTTSModelColab:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the multilingual TTS model optimized for Colab\"\"\"\n",
        "\n",
        "        # Use SpeechT5 as it's more stable and memory-efficient\n",
        "        self.model_name = \"microsoft/speecht5_tts\"\n",
        "        self.vocoder_name = \"microsoft/speecht5_hifigan\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        print(f\"Loading model: {self.model_name}\")\n",
        "\n",
        "        # Load processor and tokenizer\n",
        "        self.processor = SpeechT5Processor.from_pretrained(self.model_name)\n",
        "\n",
        "        # Load model with memory optimization\n",
        "        self.model = SpeechT5ForTextToSpeech.from_pretrained(\n",
        "            self.model_name,\n",
        "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "            low_cpu_mem_usage=True,\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Load vocoder\n",
        "        self.vocoder = SpeechT5HifiGan.from_pretrained(\n",
        "            self.vocoder_name,\n",
        "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Enable gradient checkpointing to save memory\n",
        "        if hasattr(self.model, 'gradient_checkpointing_enable'):\n",
        "            self.model.gradient_checkpointing_enable()\n",
        "\n",
        "        # Supported languages\n",
        "        self.supported_languages = {\n",
        "            'Hindi': 'hi',\n",
        "            'Marathi': 'mr',\n",
        "            'Kannada': 'kn',\n",
        "            'Telugu': 'te',\n",
        "            'Punjabi': 'pa',\n",
        "            'English': 'en'\n",
        "        }\n",
        "\n",
        "        # Load default speaker embeddings\n",
        "        self.load_speaker_embeddings()\n",
        "\n",
        "        print(\"Model loaded successfully!\")\n",
        "\n",
        "    def load_speaker_embeddings(self):\n",
        "        \"\"\"Load speaker embeddings for different languages\"\"\"\n",
        "        try:\n",
        "            # Try to load from HuggingFace\n",
        "            embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
        "            self.speaker_embeddings = torch.tensor(embeddings_dataset[7440][\"xvector\"]).unsqueeze(0).to(self.device)\n",
        "        except:\n",
        "            # Fallback: create random embedding\n",
        "            self.speaker_embeddings = torch.randn(1, 512).to(self.device)\n",
        "\n",
        "        print(\"Speaker embeddings loaded!\")\n",
        "\n",
        "    def generate_speech(self, text: str, language: str = \"en\") -> Tuple[np.ndarray, int]:\n",
        "        \"\"\"Generate speech from text\"\"\"\n",
        "\n",
        "        # Tokenize text\n",
        "        inputs = self.processor(text=text, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        # Generate speech\n",
        "        with torch.no_grad():\n",
        "            speech = self.model.generate_speech(\n",
        "                inputs[\"input_ids\"],\n",
        "                self.speaker_embeddings,\n",
        "                vocoder=self.vocoder\n",
        "            )\n",
        "\n",
        "        # Convert to numpy and return\n",
        "        speech_np = speech.cpu().numpy()\n",
        "        sample_rate = 16000\n",
        "\n",
        "        return speech_np, sample_rate\n",
        "\n",
        "    def save_model(self, path: str):\n",
        "        \"\"\"Save the fine-tuned model\"\"\"\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        self.model.save_pretrained(path)\n",
        "        self.processor.save_pretrained(path)\n",
        "        print(f\"Model saved to {path}\")\n",
        "\n",
        "# Initialize the model\n",
        "print(\"Initializing TTS model...\")\n",
        "tts_model = IndicTTSModelColab()"
      ],
      "metadata": {
        "id": "BlFQTX_fa2I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Dataset Loading and Processing"
      ],
      "metadata": {
        "id": "CpXooW1da48G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_multilingual_dataset():\n",
        "    \"\"\"Load and process multilingual Indian language dataset\"\"\"\n",
        "\n",
        "    print(\"Loading multilingual dataset...\")\n",
        "\n",
        "    try:\n",
        "        # Try loading from VoxLingua107 dataset (has Indian languages)\n",
        "        dataset = load_dataset(\"facebook/voxpopuli\", \"hi\", split=\"train[:500]\")  # Limit for Colab\n",
        "    except:\n",
        "        # Alternative: Create a sample dataset\n",
        "        print(\"Creating sample dataset...\")\n",
        "        sample_texts = [\n",
        "            # Hindi\n",
        "            (\"‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞, ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§π‡•Ç‡§Ç‡•§\", \"hi\"),\n",
        "            (\"‡§Ü‡§ú ‡§ï‡§æ ‡§¶‡§ø‡§® ‡§¨‡§π‡•Å‡§§ ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§π‡•à‡•§\", \"hi\"),\n",
        "            (\"‡§≠‡§æ‡§∞‡§§ ‡§è‡§ï ‡§Æ‡§π‡§æ‡§® ‡§¶‡•á‡§∂ ‡§π‡•à‡•§\", \"hi\"),\n",
        "            # Marathi\n",
        "            (\"‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞, ‡§Æ‡•Ä ‡§è‡§ï ‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§Ü‡§π‡•á.\", \"mr\"),\n",
        "            (\"‡§Ü‡§ú‡§ö‡§æ ‡§¶‡§ø‡§µ‡§∏ ‡§ñ‡•Ç‡§™ ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§Ü‡§π‡•á.\", \"mr\"),\n",
        "            # Kannada\n",
        "            (\"‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞, ‡≤®‡≤æ‡≤®‡≥Å ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤ï‡≥É‡≤§‡≥ç‡≤∞‡≤ø‡≤Æ ‡≤¨‡≥Å‡≤¶‡≥ç‡≤ß‡≤ø‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü.\", \"kn\"),\n",
        "            (\"‡≤á‡≤Ç‡≤¶‡≤ø‡≤® ‡≤¶‡≤ø‡≤® ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤∏‡≥Å‡≤Ç‡≤¶‡≤∞‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü.\", \"kn\"),\n",
        "            # Telugu\n",
        "            (\"‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç, ‡∞®‡±á‡∞®‡±Å ‡∞í‡∞ï ‡∞ï‡±É‡∞§‡±ç‡∞∞‡∞ø‡∞Æ ‡∞Æ‡±á‡∞ß‡∞∏‡±ç‡∞∏‡±Å.\", \"te\"),\n",
        "            (\"‡∞à ‡∞∞‡±ã‡∞ú‡±Å ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞Ö‡∞Ç‡∞¶‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø.\", \"te\"),\n",
        "            # Punjabi\n",
        "            (\"‡®∏‡®§ ‡®∏‡©ç‡®∞‡©Ä ‡®Ö‡®ï‡®æ‡®≤, ‡®Æ‡©à‡®Ç ‡®á‡©±‡®ï ‡®®‡®ï‡®≤‡©Ä ‡®¨‡©Å‡©±‡®ß‡©Ä ‡®π‡®æ‡®Ç‡•§\", \"pa\"),\n",
        "            (\"‡®Ö‡©±‡®ú ‡®¶‡®æ ‡®¶‡®ø‡®® ‡®¨‡®π‡©Å‡®§ ‡®∏‡©Å‡©∞‡®¶‡®∞ ‡®π‡©à‡•§\", \"pa\"),\n",
        "            # English\n",
        "            (\"Hello, I am an artificial intelligence.\", \"en\"),\n",
        "            (\"Today is a beautiful day.\", \"en\"),\n",
        "        ]\n",
        "\n",
        "        # Create dataset from samples\n",
        "        texts = [item[0] for item in sample_texts]\n",
        "        languages = [item[1] for item in sample_texts]\n",
        "\n",
        "        dataset_dict = {\n",
        "            'text': texts,\n",
        "            'language': languages,\n",
        "        }\n",
        "\n",
        "        dataset = Dataset.from_dict(dataset_dict)\n",
        "\n",
        "    print(f\"Dataset loaded with {len(dataset)} samples\")\n",
        "    return dataset\n",
        "\n",
        "def preprocess_dataset(dataset):\n",
        "    \"\"\"Preprocess dataset for training\"\"\"\n",
        "\n",
        "    def preprocess_function(examples):\n",
        "        # Process text inputs\n",
        "        texts = examples['text'] if isinstance(examples['text'], list) else [examples['text']]\n",
        "\n",
        "        # Tokenize texts\n",
        "        model_inputs = tts_model.processor(\n",
        "            text=texts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': model_inputs['input_ids'],\n",
        "            'attention_mask': model_inputs['attention_mask'],\n",
        "            'text': texts,\n",
        "            'language': examples['language'] if isinstance(examples['language'], list) else [examples['language']]\n",
        "        }\n",
        "\n",
        "    # Process dataset\n",
        "    processed_dataset = dataset.map(\n",
        "        preprocess_function,\n",
        "        batched=True,\n",
        "        remove_columns=dataset.column_names\n",
        "    )\n",
        "\n",
        "    return processed_dataset\n",
        "\n",
        "# Load and preprocess data\n",
        "print(\"Loading training data...\")\n",
        "raw_dataset = load_multilingual_dataset()\n",
        "processed_dataset = preprocess_dataset(raw_dataset)\n",
        "\n",
        "# Split into train/validation\n",
        "train_test_split = processed_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_dataset = train_test_split['train']\n",
        "eval_dataset = train_test_split['test']\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Eval samples: {len(eval_dataset)}\")"
      ],
      "metadata": {
        "id": "DS3TqAkDa-2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7: Memory Monitoring Utilities"
      ],
      "metadata": {
        "id": "EK4MEkwgdVFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_memory_usage():\n",
        "    \"\"\"Monitor GPU memory usage\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "        print(f\"GPU Memory - Allocated: {allocated:.2f}GB, Reserved: {reserved:.2f}GB\")\n",
        "    else:\n",
        "        print(\"CPU mode - no GPU memory to monitor\")\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear GPU memory cache\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"GPU memory cache cleared\")\n",
        "\n",
        "# Check initial memory usage\n",
        "check_memory_usage()"
      ],
      "metadata": {
        "id": "Xfcn7Uxed5r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 8: Training Configuration"
      ],
      "metadata": {
        "id": "vNRHCpsBd8ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TTSTrainer:\n",
        "    def __init__(self, model, train_dataset, eval_dataset):\n",
        "        self.model = model\n",
        "        self.train_dataset = train_dataset\n",
        "        self.eval_dataset = eval_dataset\n",
        "\n",
        "    def setup_training_args(self):\n",
        "        \"\"\"Setup training arguments optimized for Colab\"\"\"\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=\"/content/drive/MyDrive/TTS_Models/indic-tts-finetuned\",\n",
        "            per_device_train_batch_size=1,  # Very small for Colab\n",
        "            per_device_eval_batch_size=1,\n",
        "            gradient_accumulation_steps=4,   # Effective batch size = 4\n",
        "            num_train_epochs=3,              # Reduced for Colab\n",
        "            warmup_steps=100,\n",
        "            learning_rate=5e-5,\n",
        "            weight_decay=0.01,\n",
        "            logging_steps=10,\n",
        "            evaluation_strategy=\"steps\",\n",
        "            eval_steps=50,\n",
        "            save_steps=100,\n",
        "            save_total_limit=2,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"eval_loss\",\n",
        "            greater_is_better=False,\n",
        "            fp16=torch.cuda.is_available(),  # Use FP16 only if GPU available\n",
        "            dataloader_num_workers=0,        # Avoid multiprocessing issues in Colab\n",
        "            remove_unused_columns=False,\n",
        "            report_to=None,                  # Disable wandb/tensorboard\n",
        "            push_to_hub=False,\n",
        "        )\n",
        "\n",
        "        return training_args\n",
        "\n",
        "    def data_collator(self, features):\n",
        "        \"\"\"Custom data collator for TTS training\"\"\"\n",
        "        batch = {}\n",
        "\n",
        "        # Pad input_ids\n",
        "        input_ids = [f['input_ids'].squeeze() for f in features]\n",
        "        max_length = max(len(ids) for ids in input_ids)\n",
        "\n",
        "        padded_input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        for ids in input_ids:\n",
        "            pad_length = max_length - len(ids)\n",
        "            padded_ids = torch.cat([ids, torch.zeros(pad_length, dtype=ids.dtype)])\n",
        "            attention_mask = torch.cat([torch.ones(len(ids)), torch.zeros(pad_length)])\n",
        "\n",
        "            padded_input_ids.append(padded_ids)\n",
        "            attention_masks.append(attention_mask)\n",
        "\n",
        "        batch['input_ids'] = torch.stack(padded_input_ids)\n",
        "        batch['attention_mask'] = torch.stack(attention_masks)\n",
        "\n",
        "        return batch\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Start training process\"\"\"\n",
        "\n",
        "        print(\"Setting up training...\")\n",
        "        training_args = self.setup_training_args()\n",
        "\n",
        "        # Create trainer\n",
        "        trainer = Trainer(\n",
        "            model=self.model.model,\n",
        "            args=training_args,\n",
        "            train_dataset=self.train_dataset,\n",
        "            eval_dataset=self.eval_dataset,\n",
        "            data_collator=self.data_collator,\n",
        "            tokenizer=self.model.processor.tokenizer,\n",
        "        )\n",
        "\n",
        "        # Start training\n",
        "        print(\"Starting training...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            trainer.train()\n",
        "            training_time = time.time() - start_time\n",
        "            print(f\"Training completed in {training_time/60:.2f} minutes\")\n",
        "\n",
        "            # Save model\n",
        "            trainer.save_model(\"/content/drive/MyDrive/TTS_Models/final_model\")\n",
        "            print(\"Model saved successfully!\")\n",
        "\n",
        "            return trainer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Training failed with error: {e}\")\n",
        "            return None\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = TTSTrainer(tts_model, train_dataset, eval_dataset)"
      ],
      "metadata": {
        "id": "fHoWgsqxeBHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 9: Start Training (Optional - only run if you want to fine-tune)"
      ],
      "metadata": {
        "id": "MGs-b3tpeEs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WARNING: This cell will take time and may hit Colab's runtime limits\n",
        "# You can skip this cell and use the pretrained model directly\n",
        "\n",
        "# Clear memory before training\n",
        "clear_gpu_memory()\n",
        "check_memory_usage()\n",
        "\n",
        "# Start training (uncomment to run)\n",
        "# trained_model = trainer.train()\n",
        "\n",
        "print(\"Training cell ready - uncomment to start training\")\n",
        "print(\"Note: Training may take 1-3 hours depending on your GPU\")"
      ],
      "metadata": {
        "id": "EjKAgb9ZeITu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 10: Evaluation Metrics"
      ],
      "metadata": {
        "id": "iqtxCS75eLDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TTSEvaluator:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def calculate_mel_cepstral_distortion(self, generated_audio, reference_audio):\n",
        "        \"\"\"Calculate MCD between generated and reference audio\"\"\"\n",
        "        try:\n",
        "            # Ensure same length\n",
        "            min_len = min(len(generated_audio), len(reference_audio))\n",
        "            generated_audio = generated_audio[:min_len]\n",
        "            reference_audio = reference_audio[:min_len]\n",
        "\n",
        "            # Extract MFCC features\n",
        "            mfcc_gen = librosa.feature.mfcc(y=generated_audio, sr=16000, n_mfcc=13)\n",
        "            mfcc_ref = librosa.feature.mfcc(y=reference_audio, sr=16000, n_mfcc=13)\n",
        "\n",
        "            # Align feature lengths\n",
        "            min_frames = min(mfcc_gen.shape[1], mfcc_ref.shape[1])\n",
        "            mfcc_gen = mfcc_gen[:, :min_frames]\n",
        "            mfcc_ref = mfcc_ref[:, :min_frames]\n",
        "\n",
        "            # Calculate MCD\n",
        "            mcd = np.mean(np.sqrt(np.sum((mfcc_gen - mfcc_ref) ** 2, axis=0)))\n",
        "            return mcd\n",
        "        except Exception as e:\n",
        "            print(f\"MCD calculation error: {e}\")\n",
        "            return float('inf')\n",
        "\n",
        "    def calculate_real_time_factor(self, text, language):\n",
        "        \"\"\"Calculate Real-Time Factor (RTF)\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Generate speech\n",
        "        audio, sr = self.model.generate_speech(text, language)\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "        audio_duration = len(audio) / sr\n",
        "\n",
        "        rtf = generation_time / audio_duration if audio_duration > 0 else float('inf')\n",
        "        return rtf\n",
        "\n",
        "    def evaluate_samples(self, test_texts, languages):\n",
        "        \"\"\"Evaluate model on test samples\"\"\"\n",
        "\n",
        "        results = {\n",
        "            'text': [],\n",
        "            'language': [],\n",
        "            'rtf': [],\n",
        "            'audio_length': [],\n",
        "            'generation_time': []\n",
        "        }\n",
        "\n",
        "        print(\"Starting evaluation...\")\n",
        "\n",
        "        for i, (text, lang) in enumerate(zip(test_texts, languages)):\n",
        "            print(f\"Evaluating sample {i+1}/{len(test_texts)}: {lang}\")\n",
        "\n",
        "            try:\n",
        "                # Measure generation time\n",
        "                start_time = time.time()\n",
        "                audio, sr = self.model.generate_speech(text, lang)\n",
        "                generation_time = time.time() - start_time\n",
        "\n",
        "                # Calculate metrics\n",
        "                audio_length = len(audio) / sr\n",
        "                rtf = generation_time / audio_length if audio_length > 0 else float('inf')\n",
        "\n",
        "                # Store results\n",
        "                results['text'].append(text[:50] + \"...\" if len(text) > 50 else text)\n",
        "                results['language'].append(lang)\n",
        "                results['rtf'].append(rtf)\n",
        "                results['audio_length'].append(audio_length)\n",
        "                results['generation_time'].append(generation_time)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error evaluating sample {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return results\n",
        "\n",
        "    def generate_report(self, results):\n",
        "        \"\"\"Generate evaluation report\"\"\"\n",
        "\n",
        "        df = pd.DataFrame(results)\n",
        "\n",
        "        if len(df) == 0:\n",
        "            print(\"No successful evaluations to report\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n=== TTS Model Evaluation Report ===\")\n",
        "        print(f\"Total samples evaluated: {len(df)}\")\n",
        "        print(f\"Languages tested: {', '.join(df['language'].unique())}\")\n",
        "\n",
        "        # Summary statistics\n",
        "        summary_stats = df.groupby('language').agg({\n",
        "            'rtf': ['mean', 'std', 'min', 'max'],\n",
        "            'audio_length': ['mean', 'std'],\n",
        "            'generation_time': ['mean', 'std']\n",
        "        }).round(4)\n",
        "\n",
        "        print(\"\\n--- Performance by Language ---\")\n",
        "        print(summary_stats)\n",
        "\n",
        "        # Overall statistics\n",
        "        print(\"\\n--- Overall Performance ---\")\n",
        "        print(f\"Average RTF: {df['rtf'].mean():.4f} (lower is better)\")\n",
        "        print(f\"Average generation time: {df['generation_time'].mean():.2f}s\")\n",
        "        print(f\"Average audio length: {df['audio_length'].mean():.2f}s\")\n",
        "\n",
        "        # Plot results\n",
        "        if len(df) > 1:\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "            # RTF by language\n",
        "            languages = df['language'].unique()\n",
        "            rtf_by_lang = [df[df['language']==lang]['rtf'].values for lang in languages]\n",
        "\n",
        "            axes[0].boxplot(rtf_by_lang, labels=languages)\n",
        "            axes[0].set_title('Real-Time Factor by Language')\n",
        "            axes[0].set_ylabel('RTF')\n",
        "            axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "            # Generation time vs audio length\n",
        "            axes[1].scatter(df['audio_length'], df['generation_time'], alpha=0.7)\n",
        "            axes[1].set_xlabel('Audio Length (seconds)')\n",
        "            axes[1].set_ylabel('Generation Time (seconds)')\n",
        "            axes[1].set_title('Generation Time vs Audio Length')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('/content/drive/MyDrive/TTS_Models/evaluation_report.png',\n",
        "                       dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "\n",
        "        return df\n",
        "\n",
        "# Initialize evaluator\n",
        "evaluator = TTSEvaluator(tts_model)\n",
        "print(\"Evaluator initialized!\")"
      ],
      "metadata": {
        "id": "AumYm8AeeOMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 11: Run Evaluation"
      ],
      "metadata": {
        "id": "ECnAcot8eVjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test samples for evaluation\n",
        "test_samples = [\n",
        "    (\"Hello, how are you today?\", \"en\"),\n",
        "    (\"‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?\", \"hi\"),\n",
        "    (\"‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞, ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§ï‡§∏‡•á ‡§Ü‡§π‡§æ‡§§?\", \"mr\"),\n",
        "    (\"‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞, ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤π‡≥á‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø?\", \"kn\"),\n",
        "    (\"‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞é‡∞≤‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å?\", \"te\"),\n",
        "    (\"‡®∏‡®§ ‡®∏‡©ç‡®∞‡©Ä ‡®Ö‡®ï‡®æ‡®≤, ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®π‡©ã?\", \"pa\"),\n",
        "]\n",
        "\n",
        "test_texts = [sample[0] for sample in test_samples]\n",
        "test_languages = [sample[1] for sample in test_samples]\n",
        "\n",
        "print(\"Running evaluation on test samples...\")\n",
        "evaluation_results = evaluator.evaluate_samples(test_texts, test_languages)\n",
        "evaluation_df = evaluator.generate_report(evaluation_results)"
      ],
      "metadata": {
        "id": "6n3PCyfWeQbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 12: User Interface Creation"
      ],
      "metadata": {
        "id": "K2TodEa9eZL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tts_interface():\n",
        "    \"\"\"Create Gradio interface for multilingual TTS\"\"\"\n",
        "\n",
        "    def text_to_speech_demo(input_text, target_language, speaker_style=\"neutral\"):\n",
        "        \"\"\"Main TTS function for the interface\"\"\"\n",
        "\n",
        "        if not input_text.strip():\n",
        "            return None, \"‚ö†Ô∏è Please enter some text\"\n",
        "\n",
        "        # Map display names to language codes\n",
        "        lang_mapping = {\n",
        "            'English': 'en',\n",
        "            'Hindi': 'hi',\n",
        "            'Marathi': 'mr',\n",
        "            'Kannada': 'kn',\n",
        "            'Telugu': 'te',\n",
        "            'Punjabi': 'pa'\n",
        "        }\n",
        "\n",
        "        lang_code = lang_mapping.get(target_language, 'en')\n",
        "\n",
        "        try:\n",
        "            # Show processing message\n",
        "            print(f\"Generating {target_language} speech for: {input_text[:50]}...\")\n",
        "\n",
        "            # Generate speech\n",
        "            start_time = time.time()\n",
        "            audio_array, sample_rate = tts_model.generate_speech(input_text, lang_code)\n",
        "            generation_time = time.time() - start_time\n",
        "\n",
        "            # Save audio file\n",
        "            output_filename = f\"generated_audio_{int(time.time())}.wav\"\n",
        "            output_path = f\"/content/{output_filename}\"\n",
        "\n",
        "            sf.write(output_path, audio_array, sample_rate)\n",
        "\n",
        "            # Calculate metrics\n",
        "            audio_duration = len(audio_array) / sample_rate\n",
        "            rtf = generation_time / audio_duration\n",
        "\n",
        "            status_message = f\"\"\"\n",
        "            ‚úÖ **Speech Generated Successfully!**\n",
        "\n",
        "            **Details:**\n",
        "            - Language: {target_language}\n",
        "            - Audio Duration: {audio_duration:.2f}s\n",
        "            - Generation Time: {generation_time:.2f}s\n",
        "            - Real-Time Factor: {rtf:.2f}x\n",
        "            - Sample Rate: {sample_rate}Hz\n",
        "            \"\"\"\n",
        "\n",
        "            return output_path, status_message\n",
        "\n",
        "        except Exception as e:\n",
        "            error_message = f\"‚ùå **Error generating speech:** {str(e)}\"\n",
        "            print(f\"TTS Error: {e}\")\n",
        "            return None, error_message\n",
        "\n",
        "    # Create the Gradio interface\n",
        "    interface = gr.Interface(\n",
        "        fn=text_to_speech_demo,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"üìù Input Text\",\n",
        "                placeholder=\"Enter text in any language (English/Hindi/Marathi/Kannada/Telugu/Punjabi)\",\n",
        "                lines=3,\n",
        "                max_lines=5\n",
        "            ),\n",
        "            gr.Dropdown(\n",
        "                label=\"üåê Target Language\",\n",
        "                choices=[\"English\", \"Hindi\", \"Marathi\", \"Kannada\", \"Telugu\", \"Punjabi\"],\n",
        "                value=\"Hindi\"\n",
        "            ),\n",
        "            gr.Dropdown(\n",
        "                label=\"üé≠ Speaker Style\",\n",
        "                choices=[\"neutral\", \"happy\", \"sad\", \"excited\"],\n",
        "                value=\"neutral\",\n",
        "                visible=False  # Hide for now as not implemented\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Audio(\n",
        "                label=\"üîä Generated Speech\",\n",
        "                type=\"filepath\"\n",
        "            ),\n",
        "            gr.Markdown(\n",
        "                label=\"üìä Generation Details\",\n",
        "                value=\"Enter text and click Submit to generate speech\"\n",
        "            )\n",
        "        ],\n",
        "        title=\"üéôÔ∏è Multilingual Indian Text-to-Speech System\",\n",
        "        description=\"\"\"\n",
        "        ### Convert text to natural speech in multiple Indian languages!\n",
        "\n",
        "        **Supported Languages:**\n",
        "        - üáÆüá≥ Hindi (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)\n",
        "        - üáÆüá≥ Marathi (‡§Æ‡§∞‡§æ‡§†‡•Ä)\n",
        "        - üáÆüá≥ Kannada (‡≤ï‡≤®‡≥ç‡≤®‡≤°)\n",
        "        - üáÆüá≥ Telugu (‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å)\n",
        "        - üáÆüá≥ Punjabi (‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä)\n",
        "        - üá¨üáß English\n",
        "\n",
        "        **Features:**\n",
        "        - High-quality neural speech synthesis\n",
        "        - Cross-lingual support (input in one language, output in another)\n",
        "        - Real-time generation metrics\n",
        "        - Optimized for Google Colab\n",
        "\n",
        "        **Usage:** Enter your text, select target language, and click Submit!\n",
        "        \"\"\",\n",
        "        examples=[\n",
        "            [\"‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞, ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§Ü‡§∞‡•ç‡§ü‡§ø‡§´‡§ø‡§∂‡§ø‡§Ø‡§≤ ‡§á‡§Ç‡§ü‡•á‡§≤‡§ø‡§ú‡•á‡§Ç‡§∏ ‡§π‡•Ç‡§Ç‡•§\", \"Hindi\"],\n",
        "            [\"Hello, I am an artificial intelligence.\", \"Hindi\"],\n",
        "            [\"Tell me a story about Akbar and Birbal\", \"Hindi\"],\n",
        "            [\"‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞, ‡§Æ‡•Ä ‡§è‡§ï ‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§Ü‡§π‡•á.\", \"Marathi\"],\n",
        "            [\"‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞, ‡≤®‡≤æ‡≤®‡≥Å ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤ï‡≥É‡≤§‡≥ç‡≤∞‡≤ø‡≤Æ ‡≤¨‡≥Å‡≤¶‡≥ç‡≤ß‡≤ø‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü.\", \"Kannada\"],\n",
        "            [\"‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç, ‡∞®‡±á‡∞®‡±Å ‡∞í‡∞ï ‡∞ï‡±É‡∞§‡±ç‡∞∞‡∞ø‡∞Æ ‡∞Æ‡±á‡∞ß‡∞∏‡±ç‡∞∏‡±Å.\", \"Telugu\"],\n",
        "            [\"‡®∏‡®§ ‡®∏‡©ç‡®∞‡©Ä ‡®Ö‡®ï‡®æ‡®≤, ‡®Æ‡©à‡®Ç ‡®á‡©±‡®ï ‡®®‡®ï‡®≤‡©Ä ‡®¨‡©Å‡©±‡®ß‡©Ä ‡®π‡®æ‡®Ç‡•§\", \"Punjabi\"],\n",
        "            [\"Today is a beautiful day.\", \"English\"],\n",
        "        ],\n",
        "        theme=gr.themes.Soft(),\n",
        "        css=\"\"\"\n",
        "        .gradio-container {\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "        }\n",
        "        .gr-button {\n",
        "            background: linear-gradient(45deg, #FF6B35, #F7931E);\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 25px;\n",
        "        }\n",
        "        .gr-button:hover {\n",
        "            transform: scale(1.05);\n",
        "        }\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Create the interface\n",
        "print(\"Creating Gradio interface...\")\n",
        "demo_interface = create_tts_interface()"
      ],
      "metadata": {
        "id": "Vs9g8zhYeYW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 13: Launch the Interface"
      ],
      "metadata": {
        "id": "otsq9V2yefpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the Gradio interface\n",
        "print(\"üöÄ Launching Multilingual TTS Interface...\")\n",
        "print(\"This will create a public link you can share!\")\n",
        "\n",
        "# Clear GPU memory before launching\n",
        "clear_gpu_memory()\n",
        "check_memory_usage()\n",
        "\n",
        "# Launch with public sharing enabled\n",
        "demo_interface.launch(\n",
        "    share=True,           # Create shareable public link\n",
        "    debug=False,          # Disable debug mode for cleaner output\n",
        "    show_error=True,      # Show errors in interface\n",
        "    server_name=\"0.0.0.0\", # Allow external connections\n",
        "    server_port=7860,     # Standard port\n",
        "    inline=False,         # Don't embed in notebook\n",
        "    width=\"100%\",         # Full width\n",
        "    height=800            # Set height\n",
        ")\n",
        "\n",
        "print(\"Interface launched! Check the public URL above to access your TTS system.\")"
      ],
      "metadata": {
        "id": "xu1_n_IiejJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 14: Test Individual Functions (Optional)"
      ],
      "metadata": {
        "id": "XyxGVNsWelql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick test of the TTS system\n",
        "def quick_test():\n",
        "    \"\"\"Quick test of the TTS functionality\"\"\"\n",
        "\n",
        "    test_cases = [\n",
        "        (\"Hello, this is a test.\", \"en\"),\n",
        "        (\"‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞, ‡§Ø‡§π ‡§è‡§ï ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§π‡•à‡•§\", \"hi\"),\n",
        "    ]\n",
        "\n",
        "    print(\"Running quick tests...\")\n",
        "\n",
        "    for text, lang in test_cases:\n",
        "        print(f\"\\nTesting: {text} ({lang})\")\n",
        "        try:\n",
        "            audio, sr = tts_model.generate_speech(text, lang)\n",
        "            print(f\"‚úÖ Success! Generated {len(audio)/sr:.2f}s of audio\")\n",
        "\n",
        "            # Play audio in Colab\n",
        "            display(IPAudio(audio, rate=sr))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed: {e}\")\n",
        "\n",
        "# Run quick test\n",
        "quick_test()"
      ],
      "metadata": {
        "id": "NT-Ou3yAeokP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 15: Save and Load Model Functions"
      ],
      "metadata": {
        "id": "K1wAk1egerAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_checkpoint():\n",
        "    \"\"\"Save model to Google Drive\"\"\"\n",
        "    try:\n",
        "        checkpoint_path = \"/content/drive/MyDrive/TTS_Models/model_checkpoint\"\n",
        "        tts_model.save_model(checkpoint_path)\n",
        "        print(f\"‚úÖ Model saved to {checkpoint_path}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error saving model: {e}\")\n",
        "        return False\n",
        "\n",
        "def load_model_checkpoint(path):\n",
        "    \"\"\"Load model from checkpoint\"\"\"\n",
        "    try:\n",
        "        # This would be implemented if we had a fine-tuned model\n",
        "        print(f\"Loading model from {path}\")\n",
        "        # Implementation depends on the saved model format\n",
        "        print(\"‚úÖ Model loaded successfully\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading model: {e}\")\n",
        "        return False\n",
        "\n",
        "# Save current model state\n",
        "print(\"Saving model checkpoint...\")\n",
        "save_success = save_model_checkpoint()\n",
        "\n",
        "if save_success:\n",
        "    print(\"Model checkpoint saved successfully!\")\n",
        "    print(\"You can download it from Google Drive: /MyDrive/TTS_Models/\")"
      ],
      "metadata": {
        "id": "81DKtxxDetol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}