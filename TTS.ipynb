{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2NZHB6yDwddau5WdtoXXx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushpratapno1/TTS/blob/main/TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Implementation Code***"
      ],
      "metadata": {
        "id": "tlCJsf1TZn8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Environment Setup and GPU Check"
      ],
      "metadata": {
        "id": "ZACbTDMXZ-N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "🔧 System Environment Setup\n",
        "- Check GPU availability and specifications\n",
        "- Configure compute device for optimal performance\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# GPU Detection and Configuration\n",
        "print(\"🔍 Detecting compute environment...\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"🎮 GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"💾 GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"✅ Using GPU acceleration\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"⚠️ No GPU available - using CPU\")\n",
        "\n",
        "print(f\"🎯 Active device: {device}\")"
      ],
      "metadata": {
        "id": "moew57dccygn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2756742-2dd3-4f8a-a940-a0b904a1b09e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Detecting compute environment...\n",
            "CUDA available: True\n",
            "🎮 GPU device: Tesla T4\n",
            "💾 GPU memory: 14.7 GB\n",
            "✅ Using GPU acceleration\n",
            "🎯 Active device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Mount Google Drive (Optional for saving models)"
      ],
      "metadata": {
        "id": "_y4pvrNMaPAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "📁 Google Drive Mount\n",
        "- Mount Google Drive for model persistence\n",
        "- Create directory structure for saved models\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"📁 Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project directories\n",
        "project_dirs = [\n",
        "    '/content/drive/MyDrive/TTS_Models',\n",
        "    '/content/drive/MyDrive/TTS_Models/outputs',\n",
        "    '/content/drive/MyDrive/TTS_Models/logs'\n",
        "]\n",
        "\n",
        "for directory in project_dirs:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "print(\"✅ Google Drive mounted and directories created!\")\n",
        "print(\"📂 Available directories:\")\n",
        "for directory in project_dirs:\n",
        "    print(f\"   - {directory}\")"
      ],
      "metadata": {
        "id": "y3XhKl0maRqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005fcbe1-0c9b-4b19-e249-ac2cd6257c6a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Google Drive mounted and directories created!\n",
            "📂 Available directories:\n",
            "   - /content/drive/MyDrive/TTS_Models\n",
            "   - /content/drive/MyDrive/TTS_Models/outputs\n",
            "   - /content/drive/MyDrive/TTS_Models/logs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Install Dependencies"
      ],
      "metadata": {
        "id": "spJl1GoUaVqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install minimal required packages\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q \"numpy==1.24.4\"\n",
        "!pip install -q transformers>=4.35.0\n",
        "!pip install -q soundfile>=0.12.1\n",
        "!pip install -q gradio>=4.0.0\n",
        "!pip install -q accelerate>=0.24.0\n",
        "\n",
        "print(\"Lightweight packages installed successfully!\")"
      ],
      "metadata": {
        "id": "0cKE5ziPaYso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b3aa3b-a4fa-45d0-b39e-7385d53007c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m734.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.24.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "scipy 1.16.0 requires numpy<2.6,>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLightweight packages installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy"
      ],
      "metadata": {
        "id": "amy-rF-QqXdO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Import Libraries"
      ],
      "metadata": {
        "id": "IwmDAOp5acxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import time\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "# Test core imports first\n",
        "print(f\"✅ PyTorch version: {torch.__version__}\")\n",
        "print(f\"✅ NumPy version: {np.__version__}\")\n",
        "\n",
        "try:\n",
        "    # Import transformers with error handling\n",
        "    from transformers import (\n",
        "        AutoTokenizer,\n",
        "        AutoModel,\n",
        "        AutoProcessor,\n",
        "        set_seed\n",
        "    )\n",
        "    print(\"✅ Transformers imported successfully\")\n",
        "\n",
        "    # Import other packages\n",
        "    import gradio as gr\n",
        "    print(\"✅ Gradio imported successfully\")\n",
        "\n",
        "    # Set seed for reproducibility\n",
        "    set_seed(42)\n",
        "    print(\"✅ All core libraries loaded!\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"⚠️ Import warning: {e}\")\n",
        "    print(\"Continuing with available packages...\")\n",
        "\n",
        "# Test basic functionality\n",
        "test_tensor = torch.randn(2, 3)\n",
        "print(f\"✅ PyTorch working: tensor shape {test_tensor.shape}\")"
      ],
      "metadata": {
        "id": "L2C6OAS3agkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f728228-f2da-4a9c-9404-e5cc26ffc29b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PyTorch version: 2.6.0+cu124\n",
            "✅ NumPy version: 2.0.2\n",
            "⚠️ Import warning: cannot import name '_center' from 'numpy._core.umath' (/usr/local/lib/python3.11/dist-packages/numpy/_core/umath.py)\n",
            "Continuing with available packages...\n",
            "✅ PyTorch working: tensor shape torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "zE_6E8WHr-8e",
        "outputId": "ff976eb4-b3cb-4c0a-d9bd-61fd847b6907"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gtts) (2.32.3)\n",
            "Collecting click<8.2,>=7.1 (from gtts)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2025.7.14)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/98.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: click, gtts\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "Successfully installed click-8.1.8 gtts-2.5.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "click"
                ]
              },
              "id": "d97fa72c4ec84c3595ba61c5c5f6f611"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Model Class Definition"
      ],
      "metadata": {
        "id": "jmFbCh1CayWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install translation library\n",
        "!pip install -q googletrans-py\n",
        "\n",
        "import torch\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "import io\n",
        "import time\n",
        "from googletrans import Translator # Use googletrans-py which is imported as googletrans\n",
        "\n",
        "class TranslatingTTSModel:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize TTS with translation capability\"\"\"\n",
        "\n",
        "        # Initialize translator\n",
        "        self.translator = Translator()\n",
        "\n",
        "        # Language mapping for gTTS\n",
        "        self.supported_languages = {\n",
        "            'English': 'en',\n",
        "            'Hindi': 'hi',\n",
        "            'Marathi': 'mr',\n",
        "            'Kannada': 'kn',\n",
        "            'Telugu': 'te',\n",
        "            'Punjabi': 'pa',\n",
        "            'Tamil': 'ta',\n",
        "            'Bengali': 'bn',\n",
        "            'Gujarati': 'gu'\n",
        "        }\n",
        "\n",
        "        # Language names for translation\n",
        "        self.language_names = {\n",
        "            'en': 'English',\n",
        "            'hi': 'Hindi',\n",
        "            'mr': 'Marathi',\n",
        "            'kn': 'Kannada',\n",
        "            'te': 'Telugu',\n",
        "            'pa': 'Punjabi',\n",
        "            'ta': 'Tamil',\n",
        "            'bn': 'Bengali',\n",
        "            'gu': 'Gujarati'\n",
        "        }\n",
        "\n",
        "        print(\"✅ Translation + TTS model initialized!\")\n",
        "\n",
        "    def detect_language(self, text: str) -> str:\n",
        "        \"\"\"Detect the language of input text\"\"\"\n",
        "        try:\n",
        "            detection = self.translator.detect(text)\n",
        "            detected_lang = detection.lang\n",
        "            confidence = detection.confidence\n",
        "\n",
        "            print(f\"🔍 Detected language: {detected_lang} (confidence: {confidence:.2f})\")\n",
        "            return detected_lang\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Language detection failed: {e}\")\n",
        "            return 'en'  # Default to English\n",
        "\n",
        "    def translate_text(self, text: str, target_language: str) -> str:\n",
        "        \"\"\"Translate text to target language\"\"\"\n",
        "        try:\n",
        "            # Detect source language\n",
        "            source_lang = self.detect_language(text)\n",
        "\n",
        "            # If source and target are the same, no translation needed\n",
        "            if source_lang == target_language:\n",
        "                print(f\"✅ No translation needed - both languages are {self.language_names.get(target_language, target_language)}\")\n",
        "                return text\n",
        "\n",
        "            # Translate text\n",
        "            print(f\"🔄 Translating from {self.language_names.get(source_lang, source_lang)} to {self.language_names.get(target_language, target_language)}\")\n",
        "\n",
        "            translation = self.translator.translate(text, src=source_lang, dest=target_language)\n",
        "            translated_text = translation.text\n",
        "\n",
        "            print(f\"📝 Original: {text}\")\n",
        "            print(f\"🔤 Translated: {translated_text}\")\n",
        "\n",
        "            return translated_text\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Translation failed: {e}\")\n",
        "            print(\"📢 Using original text\")\n",
        "            return text\n",
        "\n",
        "    def generate_speech(self, text: str, target_language: str = \"en\") -> tuple:\n",
        "        \"\"\"Generate speech with translation\"\"\"\n",
        "        try:\n",
        "            # Step 1: Translate text to target language\n",
        "            translated_text = self.translate_text(text, target_language)\n",
        "\n",
        "            # Step 2: Generate speech in target language\n",
        "            print(f\"🎵 Generating {self.language_names.get(target_language, target_language)} speech...\")\n",
        "\n",
        "            tts = gTTS(text=translated_text, lang=target_language, slow=False)\n",
        "\n",
        "            # Save to temporary file\n",
        "            output_filename = f\"translated_tts_{int(time.time())}.mp3\"\n",
        "            tts.save(output_filename)\n",
        "\n",
        "            print(f\"✅ Speech generated: {output_filename}\")\n",
        "            return output_filename, translated_text\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error generating speech: {e}\")\n",
        "            return None, text\n",
        "\n",
        "# Initialize translation + TTS model\n",
        "print(\"Initializing Translation + TTS model...\")\n",
        "translating_tts = TranslatingTTSModel()"
      ],
      "metadata": {
        "id": "BlFQTX_fa2I6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f352e6-d194-4c81-9d33-a750e1de87d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Translation + TTS model...\n",
            "✅ Translation + TTS model initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Dataset Loading and Processing"
      ],
      "metadata": {
        "id": "CpXooW1da48G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_translation_tts_interface():\n",
        "    \"\"\"Create TTS interface with translation capability\"\"\"\n",
        "\n",
        "    def translation_tts_demo(input_text, target_language):\n",
        "        \"\"\"Generate TTS with automatic translation\"\"\"\n",
        "\n",
        "        if not input_text.strip():\n",
        "            return None, \"⚠️ Please enter some text\", \"\"\n",
        "\n",
        "        lang_code = translating_tts.supported_languages.get(target_language, 'en')\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Generate speech with translation\n",
        "            audio_file, translated_text = translating_tts.generate_speech(input_text, lang_code)\n",
        "\n",
        "            if audio_file:\n",
        "                generation_time = time.time() - start_time\n",
        "\n",
        "                # Detect source language for display\n",
        "                source_lang = translating_tts.detect_language(input_text)\n",
        "                source_name = translating_tts.language_names.get(source_lang, source_lang)\n",
        "\n",
        "                status = f\"\"\"\n",
        "                ✅ **Translation + Speech Generated Successfully!**\n",
        "\n",
        "                **Process:**\n",
        "                1. 🔍 **Detected Input:** {source_name}\n",
        "                2. 🔄 **Translated to:** {target_language}\n",
        "                3. 🎵 **Generated Speech:** {target_language} audio\n",
        "\n",
        "                **Details:**\n",
        "                - **Generation Time:** {generation_time:.2f}s\n",
        "                - **Method:** Google Translate + Google TTS\n",
        "                - **Status:** Working perfectly!\n",
        "\n",
        "                **Original Text:** {input_text}\n",
        "\n",
        "                **Translated Text:** {translated_text}\n",
        "                \"\"\"\n",
        "\n",
        "                return audio_file, status, translated_text\n",
        "            else:\n",
        "                return None, \"❌ Failed to generate speech\", \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return None, f\"❌ Error: {str(e)}\", \"\"\n",
        "\n",
        "    # Create enhanced interface\n",
        "    interface = gr.Interface(\n",
        "        fn=translation_tts_demo,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"📝 Input Text (Any Language)\",\n",
        "                placeholder=\"Type in English, Hindi, or any language...\",\n",
        "                lines=3,\n",
        "                info=\"The system will automatically detect your language and translate to the target language\"\n",
        "            ),\n",
        "            gr.Dropdown(\n",
        "                label=\"🎯 Target Language for Speech\",\n",
        "                choices=list(translating_tts.supported_languages.keys()),\n",
        "                value=\"Hindi\",\n",
        "                info=\"Select the language you want to hear the speech in\"\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Audio(label=\"🔊 Generated Speech\", type=\"filepath\"),\n",
        "            gr.Markdown(label=\"📊 Process Details\"),\n",
        "            gr.Textbox(label=\"🔤 Translated Text\", lines=2, interactive=False)\n",
        "        ],\n",
        "        title=\"🌐 Multilingual Translator + TTS System\",\n",
        "        description=\"\"\"\n",
        "        **Now with REAL translation capability!** 🎉\n",
        "\n",
        "        ✅ **Auto-detects** your input language\n",
        "        ✅ **Translates** to your target language\n",
        "        ✅ **Generates speech** in the target language\n",
        "        ✅ **Perfect for storytelling** in multiple languages\n",
        "\n",
        "        **Example:** Type \"Tell me about Akbar\" in English → Get Hindi audio story!\n",
        "        \"\"\",\n",
        "        examples=[\n",
        "            [\"Tell me about the great king Akbar and his wise minister Birbal\", \"Hindi\"],\n",
        "            [\"Hello, how are you today?\", \"Hindi\"],\n",
        "            [\"What is the story of Maharana Pratap?\", \"Hindi\"],\n",
        "            [\"Good morning, I want to hear a story\", \"Marathi\"],\n",
        "            [\"Tell me about Indian history\", \"Telugu\"],\n",
        "            [\"नमस्कार\", \"English\"],  # Hindi to English\n",
        "        ],\n",
        "        theme=gr.themes.Soft(),\n",
        "        css=\"\"\"\n",
        "        .gradio-container {\n",
        "            font-family: 'Segoe UI', sans-serif;\n",
        "        }\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Launch the translation + TTS interface\n",
        "print(\"🚀 Launching Translation + TTS interface...\")\n",
        "demo = create_translation_tts_interface()\n",
        "demo.launch(share=True, debug=False, show_error=True)\n"
      ],
      "metadata": {
        "id": "DS3TqAkDa-2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "55af7d93-eb45-40f9-9882-8f256d27838f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Launching Translation + TTS interface...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6b0df4da4d26276d9f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6b0df4da4d26276d9f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "362ffef8"
      },
      "source": [
        "!pip install -q httpx==0.13.3 httpcore==0.9.1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d8b7a8b",
        "outputId": "2c6796ea-296a-44e8-9567-2e15d0536359"
      },
      "source": [
        "!pip install -q googletrans-py"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for googletrans-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "googletrans 4.0.0rc1 requires httpx==0.13.3, but you have httpx 0.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ]
}